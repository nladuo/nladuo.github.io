<!DOCTYPE html>
<html lang="" color-mode="light">

  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="keywords" content="" />
  <meta name="author" content="叁公子KCN" />
  <meta name="description" content="" />
  
  
  <title>
    
      使用Python对音频进行特征提取 
      
      
      |
    
     叁公子的博客
  </title>

  
    <link rel="apple-touch-icon" href="/images/favicon.png">
    <link rel="icon" href="/images/favicon.png">
  

  <!-- Raleway-Font -->
  <link href="https://fonts.googleapis.com/css?family=Raleway&display=swap" rel="stylesheet">

  <!-- hexo site css -->
  <link rel="stylesheet" href="/css/main.css" />
  <link rel="stylesheet" href="//at.alicdn.com/t/font_1886449_67xjft27j1l.css" />
  <!-- 代码块风格 -->
  

  <!-- jquery3.3.1 -->
  
    <script defer type="text/javascript" src="/plugins/jquery.min.js"></script>
  

  <!-- fancybox -->
  
    <link href="/plugins/jquery.fancybox.min.css" rel="stylesheet">
    <script defer type="text/javascript" src="/plugins/jquery.fancybox.min.js"></script>
  
  
<script src="../../../../js/fancybox.js"></script>


  

  

  <script>
    var html = document.documentElement
    const colorMode = localStorage.getItem('color-mode')
    if (colorMode) {
      document.documentElement.setAttribute('color-mode', colorMode)
    }
  </script>
<meta name="generator" content="Hexo 6.3.0"></head>


  <body>
    <div id="app">
      <div class="header">
  <div class="avatar">
    <a href="/">
      <!-- 头像取消懒加载，添加no-lazy -->
      
        <img src="/images/avatar.png" alt="">
      
    </a>
    <div class="nickname"><a href="/"></a></div>
  </div>
  <div class="navbar">
    <ul>
      
        <li class="nav-item" data-path="/">
          <a href="/">Home</a>
        </li>
      
        <li class="nav-item" data-path="/archives/">
          <a href="/archives/">Archives</a>
        </li>
      
    </ul>
  </div>
</div>


<script src="../../../../js/activeNav.js"></script>



      <div class="flex-container">
        <!-- 文章详情页，展示文章具体内容，url形式：https://yoursite/文章标题/ -->
<!-- 同时为「标签tag」，「朋友friend」，「分类categories」，「关于about」页面的承载页面，具体展示取决于page.type -->


  <!-- LaTex Display -->

  
    <script async type="text/javascript" src="/plugins/mathjax/tex-chtml.js"></script>
  
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    }
  </script>





  <!-- clipboard -->

  
    <script async type="text/javascript" src="/plugins/clipboard.min.js"></script>
  
  
<script src="../../../../js/codeCopy.js"></script>







  

  

  

  
  <!-- 文章内容页 url形式：https://yoursite/文章标题/ -->
  <div class="container post-details" id="post-details">
    <div class="post-content">
      <div class="post-title">使用Python对音频进行特征提取</div>
      <div class="post-attach">
        <span class="post-pubtime">
          <i class="iconfont icon-updatetime mr-10" title="Update time"></i>
          2019-08-31 10:00:39
        </span>
        
      </div>
      <div class="markdown-body">
        <h2 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h2><p>因为喜欢玩儿音乐游戏，所以打算研究一下如何用深度学习的模型生成音游的谱面。这篇文章主要目的是介绍或者总结一些音频的知识和代码。</p>
<p>恩。如果没玩儿过的话，音乐游戏大概是下面这个样子。</p>
<p><img src="/cytus2.gif"></p>
<p>下面进入正题。</p>
<p>我Google了一下，找到了这篇文章：<a target="_blank" rel="noopener" href="https://towardsdatascience.com/extract-features-of-music-75a3f9bc265d">Music Feature Extraction in Python</a>。然后这篇文章介绍完了还有一个歌曲分类的实践：<a target="_blank" rel="noopener" href="https://medium.com/@sdoshi579/classification-of-music-into-different-genres-using-keras-82ab5339efe0">Classification of Music into different Genres using Keras</a>。</p>
<p>下面的内容会主要参考一下这两篇文章，并加入一些我的理解。内容如下：</p>
<ul>
<li>声音信号介绍</li>
<li>使用Python对音频进行特征提取</li>
<li>使用Keras对歌曲的题材进行分类</li>
</ul>
<p>主要涉及的背景知识有：</p>
<ul>
<li>傅里叶变换</li>
<li>采样定理</li>
<li>Python</li>
<li>机器学习</li>
</ul>
<span id="more"></span>
<h2 id="声音基础知识"><a href="#声音基础知识" class="headerlink" title="声音基础知识"></a>声音基础知识</h2><h3 id="音频信号"><a href="#音频信号" class="headerlink" title="音频信号"></a>音频信号</h3><p>首先先百度一下音频信号，</p>
<blockquote>
<p>音频信号是（Audio）带有语音、音乐和音效的有规律的声波的频率、幅度变化信息载体。 根据声波的特征，可把音频信息分类为规则音频和不规则声音。其中规则音频又可以分为语音、音乐和音效。规则音频是一种连续变化的模拟信号，可用一条连续的曲线来表示，称为声波。声音的三个要素是音调、音强和音色。声波或正弦波有三个重要参数：频率 $$ω_0$$、幅度$$A_n$$和相位$$ψ_n$$ ，这也就决定了音频信号的特征。</p>
</blockquote>
<p><img src="/aud.jpeg"></p>
<p>总体来说：<strong>音频信号就是不同频率和相位的正弦波的一个叠加。</strong></p>
<p>一般的声音大概就是这个样子。</p>
<p><img src="/audio.jpeg"></p>
<p>横轴是时间，纵轴是声音的幅度。因为本质上就是正弦波的一个叠加，所以看到其实是有正有负的。<br><img src="/sin.jpg"></p>
<h3 id="人耳听力频率范围"><a href="#人耳听力频率范围" class="headerlink" title="人耳听力频率范围"></a>人耳听力频率范围</h3><p>生活中存在各种正弦波，但并不是所有的波都能被人耳听到。比如说我们手机通信的信号，wifi信号，以及阳光都是一种波，但并不能被人听见。</p>
<blockquote>
<p>正常人耳听见声音的频率范围是 20Hz 到 2 万 Hz 。相同强度的声音如频率不同的话，听起来的响度是不一样的。至敏感的频率是 3000 和 4000Hz 。</p>
</blockquote>
<p>所以声波的信号基本上只要关注2wHz以内就好了。</p>
<h3 id="奈奎斯特采样定理"><a href="#奈奎斯特采样定理" class="headerlink" title="奈奎斯特采样定理"></a>奈奎斯特采样定理</h3><p>声音本质上是一种模拟信号，但在计算机或者在其他数字设备上传输时，我们要把模拟信号转换为数字信号，需要进行采样。</p>
<p>奈奎斯特采样定理如下：</p>
<blockquote>
<p>在进行模拟&#x2F;数字信号的转换过程中，当采样频率fs.max大于信号中最高频率fmax的2倍时(fs.max&gt;2fmax)，采样之后的数字信号完整地保留了原始信号中的信息。</p>
</blockquote>
<p>这个定理描述的很简单，证明其实也不难，对于声音信号，只要采样的频率大于2*2wHz&#x3D;4WHz的话，我们就可以听到无损的音质了。</p>
<p>上面说人耳听力敏感的范围主要是在4000Hz，所以我们一般听到的音乐其实是使用8000Hz频率进行采样的。这里可以看下最近比较火的芒种这首歌。<br><img src="/mangzhong.jpeg"></p>
<p>这首歌的时间是3分36秒也就是216秒，它的标准品质的大小是3.3M。这里可以计算下使用8000Hz频率，16bit进行采样的话，那么这个文件的大小是：</p>
<p>$$ 216<em>8000</em>16(bit) &#x3D; 216<em>8000</em>16&#x2F;8(字节) &#x3D; 216<em>8000</em>2&#x2F;1024&#x2F;1024(M) &#x3D; 3.296(M) $$</p>
<p>大概也就是3.3兆了。</p>
<h2 id="使用Python对音频进行特征提取"><a href="#使用Python对音频进行特征提取" class="headerlink" title="使用Python对音频进行特征提取"></a>使用Python对音频进行特征提取</h2><p>背景知识大概就上面那些，下面开始实践环节。</p>
<h3 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h3><p>这里使用到了<a target="_blank" rel="noopener" href="https://librosa.github.io/librosa/">librosa</a>，numpy, sklearn与keras。当然为了方便开发，我这里还用了IPython NoteBook。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install librosa numpy sklearn tensorflow keras</span><br></pre></td></tr></table></figure>

<h3 id="加载音乐"><a href="#加载音乐" class="headerlink" title="加载音乐"></a>加载音乐</h3><p>接下来开始在python中加载音乐，这里我选的是一首我超级喜欢的一首音游的歌曲。链接在这里：<a href="visions.mp3">visions.mp3</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> librosa</span><br><span class="line"></span><br><span class="line">x , sr = librosa.load(<span class="string">&quot;visions.mp3&quot;</span>, sr=<span class="number">8000</span>)</span><br><span class="line"><span class="built_in">print</span>(x.shape, sr)</span><br></pre></td></tr></table></figure>
<p><img src="/music_load.png"></p>
<p>这里<code>x</code>是音频信号的数字信息，可以看到是一维的，<code>sr</code>是采样频率，用8000就好了。</p>
<p>然后可以看下这首歌在时域上的波形。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> librosa.display</span><br><span class="line">plt.figure(figsize=(<span class="number">14</span>, <span class="number">5</span>))</span><br><span class="line">librosa.display.waveplot(x, sr=sr)</span><br></pre></td></tr></table></figure>
<p>运行后，效果如下：<br><img src="/music_wave.png"><br>横轴为时间，纵轴为幅度（amplitude）。</p>
<h3 id="Spectogram"><a href="#Spectogram" class="headerlink" title="Spectogram"></a>Spectogram</h3><p>上面是音乐时域上的信息。接下来需要对音乐的频率信息进行分析。</p>
<p>Spectogram这里没找到好的翻译， 大概表示的意思就是：时变的频谱图。</p>
<h4 id="短时傅里叶变换-STFT"><a href="#短时傅里叶变换-STFT" class="headerlink" title="短时傅里叶变换-STFT"></a>短时傅里叶变换-STFT</h4><p>我们知道对于周期信号，可以使用傅里叶变换可以将时间域的信息变换到频率域上。<br><img src="/ft.jpg"></p>
<p>比如说看上面这张图的这个波其实是由三个频率的正弦波构成的，可以看到从频率域的原点往上延伸，频率越来越高，可以看到对应的波形越来越密集。</p>
<p>在文章中提到了一个短时傅里叶变换的概念，作为一名本科学通信的专业学生，我也不记得老师有讲过这个变换，只记得有过离散傅里叶变换。原作者给了个视频：<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=g1_wcbGUcDY">The Short Time Fourier Transform | Digital Signal Processing</a></p>
<p>不过在看视频之前，凭借我的想象，感觉这个变换既然叫短时傅里叶变换，那应该是把音频信号拆分开，然后进行傅里叶变换。因为如果对整个音乐进行傅里叶变换的话，我们只能看到所有的频率信息，但不能确定每个频率的发生的大概时间。只能看到有某些频率的声音而已。</p>
<p>后来在网上找了一个我感觉比较好的解释：</p>
<blockquote>
<p>短时傅立叶变换基本思想是将信号加滑动时间窗，并对窗内信号做傅立叶变换，得到信号的时变频谱。</p>
</blockquote>
<p>另外，还有一个东西可以感受STFT，这里可以打开网易云音乐，找到一首歌，打开动效。<br><img src="/music_stft.jpeg"><br>可以看到不断变化的各波形，拆分开来看，其实代表着就当前这一短时间内包含的声音的频率信息。上面的这张图其实也就是对当前时刻的音频信号，进行DFT得到的。</p>
<h4 id="画出时变的频谱图"><a href="#画出时变的频谱图" class="headerlink" title="画出时变的频谱图"></a>画出时变的频谱图</h4><p>接下来我们调用librosa的stft方法可以直接得到短时傅里叶变换的结果。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">X = librosa.stft(x)</span><br><span class="line">Xdb = librosa.amplitude_to_db(<span class="built_in">abs</span>(X))   <span class="comment"># 把幅度转成分贝格式</span></span><br><span class="line">plt.figure(figsize=(<span class="number">14</span>, <span class="number">5</span>))</span><br><span class="line">librosa.display.specshow(Xdb, sr=sr, x_axis=<span class="string">&#x27;time&#x27;</span>, y_axis=<span class="string">&#x27;hz&#x27;</span>)</span><br><span class="line">plt.colorbar()</span><br></pre></td></tr></table></figure>
<p>效果如下：<br><img src="/spectogram.png"><br>这里横轴是时间，纵轴是频率，颜色则代表分贝（声音的响度），可以看到越红的地方信号音量越大。</p>
<h3 id="特征提取"><a href="#特征提取" class="headerlink" title="特征提取"></a>特征提取</h3><p>接下来，介绍了一些音乐中的主要特征，这里主要翻译原作者的内容。</p>
<h4 id="过零率（Zero-Crossing-Rate）"><a href="#过零率（Zero-Crossing-Rate）" class="headerlink" title="过零率（Zero Crossing Rate）"></a>过零率（Zero Crossing Rate）</h4><p>过零率(Zero Crossing Rate,ZCR)是指在每帧中,语音信号通过零点(从正变为负或从负变为正)的次数。这个特征已在语音识别和音乐信息检索领域得到广泛使用，是金属声音和摇滚乐的关键特征。</p>
<p>回到上面的图，我们把一个时间上放大。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">n0 = <span class="number">9000</span></span><br><span class="line">n1 = <span class="number">9100</span></span><br><span class="line">plt.figure(figsize=(<span class="number">14</span>, <span class="number">5</span>))</span><br><span class="line">plt.plot(x[n0:n1])</span><br><span class="line">plt.grid()</span><br></pre></td></tr></table></figure>
<p>效果如下：<br><img src="/zcr.png"></p>
<p>这里有7个过零点，可以通过下面的方法进行计算。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">zero_crossings = librosa.zero_crossings(x[n0:n1], pad=<span class="literal">False</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">sum</span>(zero_crossings))</span><br></pre></td></tr></table></figure>

<h4 id="频谱中心（Spectral-Centroid）"><a href="#频谱中心（Spectral-Centroid）" class="headerlink" title="频谱中心（Spectral Centroid）"></a>频谱中心（Spectral Centroid）</h4><p>频谱中心代表声音的“质心”，又称为频谱一阶距。频谱中心的值越小，表明越多的频谱能量集中在低频范围内。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#spectral centroid -- centre of mass -- weighted mean of the frequencies present in the sound</span></span><br><span class="line"><span class="keyword">import</span> sklearn</span><br><span class="line">spectral_centroids = librosa.feature.spectral_centroid(x[:<span class="number">80000</span>], sr=sr)[<span class="number">0</span>]</span><br><span class="line"><span class="comment"># Computing the time variable for visualization</span></span><br><span class="line">frames = <span class="built_in">range</span>(<span class="built_in">len</span>(spectral_centroids))</span><br><span class="line">t = librosa.frames_to_time(frames, sr=<span class="number">8000</span>)</span><br><span class="line"><span class="comment"># Normalising the spectral centroid for visualisation</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">normalize</span>(<span class="params">x, axis=<span class="number">0</span></span>):</span><br><span class="line">    <span class="keyword">return</span> sklearn.preprocessing.minmax_scale(x, axis=axis)</span><br><span class="line"><span class="comment">#Plotting the Spectral Centroid along the waveform</span></span><br><span class="line">librosa.display.waveplot(x[:<span class="number">80000</span>], sr=sr, alpha=<span class="number">0.4</span>)</span><br><span class="line">plt.plot(t, normalize(spectral_centroids), color=<span class="string">&#x27;r&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>这里用<code>x[:80000]</code>表示音乐的前10秒。</p>
<p><code>.spectral_centroid</code> 来计算每一帧的频谱中心。</p>
<p><code>.frames_to_time</code>将帧转换为时间，time[i] &#x3D;&#x3D; frame[i]。【因为stft是一个窗口(帧)一个窗口取的，和采样频率并不对应，所以有个转换】</p>
<p>为了更好的可视化，对频谱中心进行了归一化。</p>
<p><img src="/spectral_centroid.png"></p>
<h4 id="频谱滚降点（Spectral-Rolloff）"><a href="#频谱滚降点（Spectral-Rolloff）" class="headerlink" title="频谱滚降点（Spectral Rolloff）"></a>频谱滚降点（Spectral Rolloff）</h4><p>频谱滚降点的意思，我翻译过来大概是：比该频率低的频率的所有能量大于一定比例的整个频谱的能量，通常这个比例为0.85。</p>
<p>感觉还是有点儿别扭，用公式比较好理解一些。<br><img src="/rolloff.png"></p>
<p>下面看下代码，和上面频谱中心的代码其实类似，也是一帧一帧的进行特征抽取。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">spectral_rolloff = librosa.feature.spectral_rolloff(x, sr=sr)[<span class="number">0</span>]</span><br><span class="line">librosa.display.waveplot(x, sr=sr, alpha=<span class="number">0.4</span>)</span><br><span class="line">plt.plot(t, normalize(spectral_rolloff), color=<span class="string">&#x27;r&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p><code>.spectral_rolloff</code> 来计算每一帧的频谱滚降点。</p>
<p><img src="/spectral_rolloff.png"></p>
<h4 id="MFCC-梅尔频率倒谱系数"><a href="#MFCC-梅尔频率倒谱系数" class="headerlink" title="MFCC (梅尔频率倒谱系数)"></a>MFCC (梅尔频率倒谱系数)</h4><p>MFCC是音频信号特征中最重要的一个，基本上处理音频信号就会用到。（作为一名通信学士，我也是才知道的）。</p>
<p>信号的MFCC参数是一个小集合的特征（一般10-20个），它能够简洁的表示频谱的包络。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mfccs = librosa.feature.mfcc(x, sr=sr)</span><br><span class="line"><span class="built_in">print</span>(mfccs.shape)</span><br><span class="line"><span class="comment">#Displaying  the MFCCs:</span></span><br><span class="line">librosa.display.specshow(mfccs, sr=sr, x_axis=<span class="string">&#x27;time&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p><code>.mfcc</code> 用来计算信号的MFCC参数。</p>
<p>通过打印<code>mfccs.shape</code>，可以看看每一帧里面有多少维的MFCC特征。第一个参数是mfcc参数的维度，第二个参数是帧数。<br><img src="/mfcc.png"></p>
<p>这里一共3177帧，每一帧有20维特征。</p>
<h2 id="使用Keras对歌曲的题材进行分类"><a href="#使用Keras对歌曲的题材进行分类" class="headerlink" title="使用Keras对歌曲的题材进行分类"></a>使用Keras对歌曲的题材进行分类</h2><p>接下来，完成了以上的对音频信号的特征提取，就可以进行一波机器学习了。（这里不会涉及到机器学习的背景知识，默认读者不是机器学习的小白。）<br><img src="/ml_workflow.png"></p>
<h3 id="数据准备"><a href="#数据准备" class="headerlink" title="数据准备"></a>数据准备</h3><h4 id="数据集下载"><a href="#数据集下载" class="headerlink" title="数据集下载"></a>数据集下载</h4><p>这里将要使用<a target="_blank" rel="noopener" href="http://opihi.cs.uvic.ca/sound/genres.tar.gz">GTZAN genre collection</a>。这个数据集包含了10个题材，每个题材包含了100个30s长的音乐。</p>
<p>这里将使用Tensorflow后端的Keras进行编码。</p>
<h4 id="加载数据到内存"><a href="#加载数据到内存" class="headerlink" title="加载数据到内存"></a>加载数据到内存</h4><p>这里首先加载这些数据。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> librosa</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">genres = <span class="string">&#x27;blues classical country disco hiphop jazz metal pop reggae rock&#x27;</span>.split()</span><br><span class="line"></span><br><span class="line">data_set = []</span><br><span class="line">label_set = []</span><br><span class="line"></span><br><span class="line">label2id = &#123;genre:i <span class="keyword">for</span> i,genre <span class="keyword">in</span> <span class="built_in">enumerate</span>(genres)&#125;</span><br><span class="line">id2label = &#123;i:genre <span class="keyword">for</span> i,genre <span class="keyword">in</span> <span class="built_in">enumerate</span>(genres)&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(label2id)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> g <span class="keyword">in</span> genres:</span><br><span class="line">    <span class="built_in">print</span>(g)</span><br><span class="line">    <span class="keyword">for</span> filename <span class="keyword">in</span> os.listdir(<span class="string">f&#x27;./genres/<span class="subst">&#123;g&#125;</span>/&#x27;</span>):</span><br><span class="line">        songname = <span class="string">f&#x27;./genres/<span class="subst">&#123;g&#125;</span>/<span class="subst">&#123;filename&#125;</span>&#x27;</span></span><br><span class="line">        y, sr = librosa.load(songname, mono=<span class="literal">True</span>, duration=<span class="number">30</span>)</span><br><span class="line">        chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)</span><br><span class="line">        rmse = librosa.feature.rms(y=y)</span><br><span class="line">        spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)</span><br><span class="line">        spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)</span><br><span class="line">        rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)</span><br><span class="line">        zcr = librosa.feature.zero_crossing_rate(y)</span><br><span class="line">        mfcc = librosa.feature.mfcc(y=y, sr=sr)</span><br><span class="line"></span><br><span class="line">        to_append = <span class="string">f&#x27;<span class="subst">&#123;np.mean(chroma_stft)&#125;</span> <span class="subst">&#123;np.mean(rmse)&#125;</span> <span class="subst">&#123;np.mean(spec_cent)&#125;</span> <span class="subst">&#123;np.mean(spec_bw)&#125;</span> <span class="subst">&#123;np.mean(rolloff)&#125;</span> <span class="subst">&#123;np.mean(zcr)&#125;</span>&#x27;</span>    </span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> e <span class="keyword">in</span> mfcc:</span><br><span class="line">            to_append += <span class="string">f&#x27; <span class="subst">&#123;np.mean(e)&#125;</span>&#x27;</span></span><br><span class="line"></span><br><span class="line">        data_set.append([<span class="built_in">float</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> to_append.split(<span class="string">&quot; &quot;</span>)])</span><br><span class="line">        label_set.append(label2id[g])</span><br></pre></td></tr></table></figure>
<p>可以看到除了上面讲到的一些特征之外，原作者这里还说了一些其他的特征，比如说rmse，chroma_stft这种。这里就不再一一介绍了。</p>
<p>总体来说，这里使用chroma_stft，rmse，spec_cent，spec_bw，rolloff，zcr的六个特征的均值，再加上mfcc的20个特征的均值，总共26个特征，来表示一个音乐的。</p>
<h4 id="创建数据集"><a href="#创建数据集" class="headerlink" title="创建数据集"></a>创建数据集</h4><p>接下来我们对数据进行一下归一化，对标签进行one-hot编码。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> np_utils</span><br><span class="line"></span><br><span class="line">scaler = StandardScaler()</span><br><span class="line">X = scaler.fit_transform(np.array(data_set, dtype = <span class="built_in">float</span>))</span><br><span class="line">y = np_utils.to_categorical(np.array(label_set))</span><br></pre></td></tr></table></figure>
<p>效果如下：<br><img src="/dataset.png"></p>
<p>然后把测试集和训练集进行分割。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>)</span><br></pre></td></tr></table></figure>

<h3 id="创建模型"><a href="#创建模型" class="headerlink" title="创建模型"></a>创建模型</h3><p>这里的我们的特征很少，所以用几层神经网络就可以了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense, Dropout</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_model</span>():</span><br><span class="line">    model = models.Sequential()</span><br><span class="line">    model.add(Dense(<span class="number">256</span>, activation=<span class="string">&#x27;relu&#x27;</span>, input_shape=(X_train.shape[<span class="number">1</span>],)))</span><br><span class="line">    model.add(Dense(<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(Dropout(<span class="number">0.5</span>))</span><br><span class="line">    model.add(Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line">model = create_model()</span><br></pre></td></tr></table></figure>

<p>这里创建了一个包含三个隐藏层的神经网络，最后一层输出的是分类层，因为是10类，所以最后一层是10个单元。（这里相比原作者的代码多了一层Dropout减少数据过拟合）</p>
<h3 id="编译模型"><a href="#编译模型" class="headerlink" title="编译模型"></a>编译模型</h3><p>然后是编译模型，我们这里是一个分类问题，所以使用类别交叉熵函数<code>categorical_crossentropy</code>，然后优化器选择Adam，评价指标选择正确率。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>,</span><br><span class="line">              loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>,</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br></pre></td></tr></table></figure>

<h3 id="训练与评估"><a href="#训练与评估" class="headerlink" title="训练与评估"></a>训练与评估</h3><p>接下来使用<code>fit</code>方法进行训练，训练50轮。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.fit(X_train, y_train, epochs=<span class="number">50</span>, batch_size=<span class="number">128</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/train_acc.png"></p>
<p>训练很快就完了，然后使用<code>evaluate</code>方法进行评估。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">test_loss, test_acc = model.evaluate(X_test,y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;test_acc: &#x27;</span>,test_acc)</span><br></pre></td></tr></table></figure>
<p><img src="/test_acc.png"></p>
<p>这里的测试准确率也就百分之70不到，原作者后面还有使用模型预测的代码，感觉都没有必要了。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>这篇博客主要是介绍了一些声音方面的特征提取的知识和代码，关于最后的案例看着玩玩儿就行，基本不具有实用性。</p>

      </div>
      
        <div class="prev-or-next">
          <div class="post-foot-next">
            
              <a href="../../../05/20/ElasticSearch-Connection-Timeout%E9%97%AE%E9%A2%98%E7%9A%84%E4%B8%80%E4%B8%AA%E7%A5%9E%E5%A5%87%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/" target="_self">
                <i class="iconfont icon-chevronleft"></i>
                <span>Prev</span>
              </a>
            
          </div>
          <div class="post-attach">
            <span class="post-pubtime">
              <i class="iconfont icon-updatetime mr-10" title="Update time"></i>
              2019-08-31 10:00:39
            </span>
            
          </div>
          <div class="post-foot-prev">
            
              <a href="../../../11/17/%E5%9B%BE%E5%83%8F%E6%90%9C%E7%B4%A2%EF%BC%9A%E7%BB%99%E4%BD%A0%E7%88%AC%E7%9A%84%E7%BE%8E%E5%A5%B3%E5%9B%BE%E5%BB%BA%E4%B8%80%E4%B8%AA%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E/" target="_self">
                <span>Next</span>
                <i class="iconfont icon-chevronright"></i>
              </a>
            
          </div>
        </div>
      
    </div>
    
  <div id="btn-catalog" class="btn-catalog">
    <i class="iconfont icon-catalog"></i>
  </div>
  <div class="post-catalog hidden" id="catalog">
    <div class="title">Contents</div>
    <div class="catalog-content">
      
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%86%99%E5%9C%A8%E5%89%8D%E9%9D%A2"><span class="toc-text">写在前面</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A3%B0%E9%9F%B3%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86"><span class="toc-text">声音基础知识</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9F%B3%E9%A2%91%E4%BF%A1%E5%8F%B7"><span class="toc-text">音频信号</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%BA%E8%80%B3%E5%90%AC%E5%8A%9B%E9%A2%91%E7%8E%87%E8%8C%83%E5%9B%B4"><span class="toc-text">人耳听力频率范围</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A5%88%E5%A5%8E%E6%96%AF%E7%89%B9%E9%87%87%E6%A0%B7%E5%AE%9A%E7%90%86"><span class="toc-text">奈奎斯特采样定理</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8Python%E5%AF%B9%E9%9F%B3%E9%A2%91%E8%BF%9B%E8%A1%8C%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96"><span class="toc-text">使用Python对音频进行特征提取</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%87%86%E5%A4%87%E5%B7%A5%E4%BD%9C"><span class="toc-text">准备工作</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8A%A0%E8%BD%BD%E9%9F%B3%E4%B9%90"><span class="toc-text">加载音乐</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Spectogram"><span class="toc-text">Spectogram</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%9F%AD%E6%97%B6%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2-STFT"><span class="toc-text">短时傅里叶变换-STFT</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%94%BB%E5%87%BA%E6%97%B6%E5%8F%98%E7%9A%84%E9%A2%91%E8%B0%B1%E5%9B%BE"><span class="toc-text">画出时变的频谱图</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96"><span class="toc-text">特征提取</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BF%87%E9%9B%B6%E7%8E%87%EF%BC%88Zero-Crossing-Rate%EF%BC%89"><span class="toc-text">过零率（Zero Crossing Rate）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%A2%91%E8%B0%B1%E4%B8%AD%E5%BF%83%EF%BC%88Spectral-Centroid%EF%BC%89"><span class="toc-text">频谱中心（Spectral Centroid）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%A2%91%E8%B0%B1%E6%BB%9A%E9%99%8D%E7%82%B9%EF%BC%88Spectral-Rolloff%EF%BC%89"><span class="toc-text">频谱滚降点（Spectral Rolloff）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#MFCC-%E6%A2%85%E5%B0%94%E9%A2%91%E7%8E%87%E5%80%92%E8%B0%B1%E7%B3%BB%E6%95%B0"><span class="toc-text">MFCC (梅尔频率倒谱系数)</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8Keras%E5%AF%B9%E6%AD%8C%E6%9B%B2%E7%9A%84%E9%A2%98%E6%9D%90%E8%BF%9B%E8%A1%8C%E5%88%86%E7%B1%BB"><span class="toc-text">使用Keras对歌曲的题材进行分类</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%87%86%E5%A4%87"><span class="toc-text">数据准备</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8B%E8%BD%BD"><span class="toc-text">数据集下载</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE%E5%88%B0%E5%86%85%E5%AD%98"><span class="toc-text">加载数据到内存</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-text">创建数据集</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E6%A8%A1%E5%9E%8B"><span class="toc-text">创建模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%96%E8%AF%91%E6%A8%A1%E5%9E%8B"><span class="toc-text">编译模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E4%B8%8E%E8%AF%84%E4%BC%B0"><span class="toc-text">训练与评估</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-text">总结</span></a></li></ol>
      
    </div>
  </div>

  
<script src="../../../../js/catalog.js"></script>




    
      <div class="comments-container">
        







      </div>
    
  </div>


        
<div class="footer">
  <div class="social">
    <ul>
      
        <li>
          <a title="github" target="_blank" rel="noopener" href="https://github.com/zchengsite/hexo-theme-oranges">
            <i class="iconfont icon-github"></i>
          </a>
        </li>
      
    </ul>
  </div>
  
    
    <div class="footer-more">
      
        <a target="_blank" rel="noopener" href="http://www.beian.miit.gov.cn/">http://www.beian.miit.gov.cn/  京ICP备17062395号</a>
        
    </div>
  
  
</div>

      </div>

      <div class="tools-bar">
        <div class="back-to-top tools-bar-item hidden">
  <a href="javascript: void(0)">
    <i class="iconfont icon-chevronup"></i>
  </a>
</div>


<script src="../../../../js/backtotop.js"></script>



        
  <div class="search-icon tools-bar-item" id="search-icon">
    <a href="javascript: void(0)">
      <i class="iconfont icon-search"></i>
    </a>
  </div>

  <div class="search-overlay hidden">
    <div class="search-content" tabindex="0">
      <div class="search-title">
        <span class="search-icon-input">
          <a href="javascript: void(0)">
            <i class="iconfont icon-search"></i>
          </a>
        </span>
        
          <input type="text" class="search-input" id="search-input" placeholder="Search...">
        
        <span class="search-close-icon" id="search-close-icon">
          <a href="javascript: void(0)">
            <i class="iconfont icon-close"></i>
          </a>
        </span>
      </div>
      <div class="search-result" id="search-result"></div>
    </div>
  </div>

  <script type="text/javascript">
    var inputArea = document.querySelector("#search-input")
    var searchOverlayArea = document.querySelector(".search-overlay")

    inputArea.onclick = function() {
      getSearchFile()
      this.onclick = null
    }

    inputArea.onkeydown = function() {
      if(event.keyCode == 13)
        return false
    }

    function openOrHideSearchContent() {
      let isHidden = searchOverlayArea.classList.contains('hidden')
      if (isHidden) {
        searchOverlayArea.classList.remove('hidden')
        document.body.classList.add('hidden')
        // inputArea.focus()
      } else {
        searchOverlayArea.classList.add('hidden')
        document.body.classList.remove('hidden')
      }
    }

    function blurSearchContent(e) {
      if (e.target === searchOverlayArea) {
        openOrHideSearchContent()
      }
    }

    document.querySelector("#search-icon").addEventListener("click", openOrHideSearchContent, false)
    document.querySelector("#search-close-icon").addEventListener("click", openOrHideSearchContent, false)
    searchOverlayArea.addEventListener("click", blurSearchContent, false)

    var searchFunc = function (path, search_id, content_id) {
      'use strict';
      var $input = document.getElementById(search_id);
      var $resultContent = document.getElementById(content_id);
      $resultContent.innerHTML = "<ul><span class='local-search-empty'>First search, index file loading, please wait...<span></ul>";
      $.ajax({
        // 0x01. load xml file
        url: path,
        dataType: "xml",
        success: function (xmlResponse) {
          // 0x02. parse xml file
          var datas = $("entry", xmlResponse).map(function () {
            return {
              title: $("title", this).text(),
              content: $("content", this).text(),
              url: $("url", this).text()
            };
          }).get();
          $resultContent.innerHTML = "";

          $input.addEventListener('input', function () {
            // 0x03. parse query to keywords list
            var str = '<ul class=\"search-result-list\">';
            var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
            $resultContent.innerHTML = "";
            if (this.value.trim().length <= 0) {
              return;
            }
            // 0x04. perform local searching
            datas.forEach(function (data) {
              var isMatch = true;
              var content_index = [];
              if (!data.title || data.title.trim() === '') {
                data.title = "Untitled";
              }
              var orig_data_title = data.title.trim();
              var data_title = orig_data_title.toLowerCase();
              var orig_data_content = data.content.trim().replace(/<[^>]+>/g, "");
              var data_content = orig_data_content.toLowerCase();
              var data_url = data.url;
              var index_title = -1;
              var index_content = -1;
              var first_occur = -1;
              // only match artiles with not empty contents
              if (data_content !== '') {
                keywords.forEach(function (keyword, i) {
                  index_title = data_title.indexOf(keyword);
                  index_content = data_content.indexOf(keyword);

                  if (index_title < 0 && index_content < 0) {
                    isMatch = false;
                  } else {
                    if (index_content < 0) {
                      index_content = 0;
                    }
                    if (i == 0) {
                      first_occur = index_content;
                    }
                    // content_index.push({index_content:index_content, keyword_len:keyword_len});
                  }
                });
              } else {
                isMatch = false;
              }
              // 0x05. show search results
              if (isMatch) {
                str += "<li><a href='" + data_url + "' class='search-result-title'>" + orig_data_title + "</a>";
                var content = orig_data_content;
                if (first_occur >= 0) {
                  // cut out 100 characters
                  var start = first_occur - 20;
                  var end = first_occur + 80;

                  if (start < 0) {
                    start = 0;
                  }

                  if (start == 0) {
                    end = 100;
                  }

                  if (end > content.length) {
                    end = content.length;
                  }

                  var match_content = content.substr(start, end);

                  // highlight all keywords
                  keywords.forEach(function (keyword) {
                    var regS = new RegExp(keyword, "gi");
                    match_content = match_content.replace(regS, "<span class=\"search-keyword\">" + keyword + "</span>");
                  });

                  str += "<p class=\"search-result-abstract\">" + match_content + "...</p>"
                }
                str += "</li>";
              }
            });
            str += "</ul>";
            if (str.indexOf('<li>') === -1) {
              return $resultContent.innerHTML = "<ul><span class='local-search-empty'>No result<span></ul>";
            }
            $resultContent.innerHTML = str;
          });
        },
        error: function(xhr, status, error) {
          $resultContent.innerHTML = ""
          if (xhr.status === 404) {
            $resultContent.innerHTML = "<ul><span class='local-search-empty'>The search.xml file was not found, please refer to：<a href='https://github.com/zchengsite/hexo-theme-oranges#configuration' target='_black'>configuration</a><span></ul>";
          } else {
            $resultContent.innerHTML = "<ul><span class='local-search-empty'>The request failed, Try to refresh the page or try again later.<span></ul>";
          }
        }
      });
      $(document).on('click', '#search-close-icon', function() {
        $('#search-input').val('');
        $('#search-result').html('');
      });
    }

    var getSearchFile = function() {
        var path = "/search.xml";
        searchFunc(path, 'search-input', 'search-result');
    }
  </script>




        
  <div class="tools-bar-item theme-icon" id="switch-color-scheme">
    <a href="javascript: void(0)">
      <i id="theme-icon" class="iconfont icon-moon"></i>
    </a>
  </div>

  
<script src="../../../../js/colorscheme.js"></script>





        
  
    <div class="share-icon tools-bar-item">
      <a href="javascript: void(0)" id="share-icon">
        <i class="iconfont iconshare"></i>
      </a>
      <div class="share-content hidden">
        
          <a class="share-item" href="https://twitter.com/intent/tweet?text=' + %E4%BD%BF%E7%94%A8Python%E5%AF%B9%E9%9F%B3%E9%A2%91%E8%BF%9B%E8%A1%8C%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96 + '&url=' + http%3A%2F%2Fnladuo.github.io%2F2019%2F08%2F31%2F%25E4%25BD%25BF%25E7%2594%25A8Python%25E5%25AF%25B9%25E9%259F%25B3%25E9%25A2%2591%25E8%25BF%259B%25E8%25A1%258C%25E7%2589%25B9%25E5%25BE%2581%25E6%258F%2590%25E5%258F%2596%2F + '" target="_blank" title="Twitter">
            <i class="iconfont icon-twitter"></i>
          </a>
        
        
          <a class="share-item" href="https://www.facebook.com/sharer.php?u=http://nladuo.github.io/2019/08/31/%E4%BD%BF%E7%94%A8Python%E5%AF%B9%E9%9F%B3%E9%A2%91%E8%BF%9B%E8%A1%8C%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96/" target="_blank" title="Facebook">
            <i class="iconfont icon-facebooksquare"></i>
          </a>
        
      </div>
    </div>
  
  
<script src="../../../../js/shares.js"></script>



      </div>
    </div>
  </body>
</html>
